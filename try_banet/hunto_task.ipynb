{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generate data batch.\"\"\"\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tables\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch(self):\n",
    "    \"\"\"Get [train_batch_size] examples as one train batch. Both question and answer\n",
    "    are converted to int. The data batch is selected from short buckets to long buckets.\"\"\"\n",
    "    vgg_batch = []\n",
    "    c3d_batch = []\n",
    "    question_batch = []\n",
    "    answer_batch = []\n",
    "\n",
    "    bucket = self.train_buckets[self.current_bucket]\n",
    "    start = self.train_batch_idx[\n",
    "        self.current_bucket] * self.train_batch_size\n",
    "    end = start + self.train_batch_size\n",
    "\n",
    "    question_encode = bucket.iloc[start:end]['question_encode'].values\n",
    "    answer_batch = bucket.iloc[start:end]['answer_encode'].values\n",
    "    video_ids = bucket.iloc[start:end]['video_id'].values\n",
    "    batch_length = self.train_batch_length[self.current_bucket]\n",
    "\n",
    "    #print(self.video_feature.root.vgg.shape, self.train_batch_size)\n",
    "    for i in range(len(question_encode)):\n",
    "        qid = [int(x) for x in question_encode[i].split(',')]\n",
    "        qid = np.pad(qid, (0, batch_length - len(qid)), 'constant')\n",
    "        question_batch.append(qid)\n",
    "        #print(max(video_ids))\n",
    "        #print(type(video_ids[i]), video_ids[i])\n",
    "        vgg_batch.append(self.video_feature.root.vgg[video_ids[i] - 1])\n",
    "        c3d_batch.append(self.video_feature.root.c3d[video_ids[i] - 1])\n",
    "\n",
    "    self.train_batch_idx[self.current_bucket] += 1\n",
    "    # if current bucket is ran out, use next bucket.\n",
    "    # print('batch_idx', self.train_batch_idx[self.current_bucket])\n",
    "    # print('current_bucket', self.current_bucket)\n",
    "    # print(self.train_batch_total)\n",
    "    if self.train_batch_idx[self.current_bucket] == self.train_batch_total[self.current_bucket]:\n",
    "        self.current_bucket += 1\n",
    "    while self.current_bucket != len(self.train_batch_total) \\\n",
    "          and self.train_batch_total[self.current_bucket] == 0:\n",
    "        # if current bucket is empty --> next bucket\n",
    "        self.current_bucket += 1\n",
    "    if self.current_bucket == len(self.train_batch_total):\n",
    "        self.has_train_batch = False\n",
    "    #print(len(question_batch))\n",
    "    # answer to one-hot like array\n",
    "    answer_onehot = np.zeros((len(answer_batch), self.answer_num), dtype=np.int64)  \n",
    "    for i, row in enumerate(answer_batch):\n",
    "        for a in row:\n",
    "            answer_onehot[i][a] = 1    \n",
    "\n",
    "    return vgg_batch, c3d_batch, question_batch, answer_onehot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[1.5,2.2]\n",
    "x=[int(x) for x in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_encode=[\"1.5,2.2\",\"6.5,2.2\"]\n",
    "q=[x.split(',') for x in question_encode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1.5', '2.2'], ['6.5', '2.2']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [6, 2]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[int(float(item)) for item in x] for x in q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '1.5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-06796f6c1248>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1.5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '1.5'"
     ]
    }
   ],
   "source": [
    "int(str('1.5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int('1.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_example(self):\n",
    "    \"\"\"Get one val example. Only question is converted to int.\"\"\"\n",
    "    start = self.val_example_idx * self.train_batch_size\n",
    "    end = start + self.train_batch_size\n",
    "\n",
    "    question_encode = self.val_qa.iloc[start:end]['question_encode']\n",
    "    video_id = self.val_qa.iloc[start:end]['video_id']\n",
    "    answer = self.val_qa.iloc[start:end]['answer']\n",
    "\n",
    "    #question = [int(x) for x in question_encode.split(',')]\n",
    "    question = [x.split(',') for x in question_encode]\n",
    "    question = [[int(item) for item in x] for x in question]\n",
    "    vgg = self.video_feature.root.vgg[video_id - 1]\n",
    "    c3d = self.video_feature.root.c3d[video_id - 1]\n",
    "\n",
    "    self.val_example_idx += 1\n",
    "    if self.val_example_idx == self.val_example_total:\n",
    "        self.has_val_example = False\n",
    "\n",
    "    answer_onehot = np.zeros((self.train_batch_size, self.answer_num), dtype=np.int64)\n",
    "    for i, ans_ in enumerate(answer):\n",
    "        for ans in ans_:\n",
    "            answer_onehot[i, self.answer_dict[ans]] = 1\n",
    "\n",
    "    return vgg, c3d, question, answer_onehot\n",
    "\n",
    "def get_test_example(self):\n",
    "    \"\"\"Get one test example. Only question is converted to int.\"\"\"\n",
    "    start=self.test_example_idx*self.train_batch_size\n",
    "    end=start+self.train_batch_size\n",
    "    example_id = self.test_qa.iloc[start:end]['id']\n",
    "    question_encode = self.test_qa.iloc[\n",
    "        start:end]['question_encode']\n",
    "    video_id = self.test_qa.iloc[start:end]['video_id']\n",
    "    answer = self.test_qa.iloc[start:end]['answer']\n",
    "\n",
    "    #question = [int(x) for x in question_encode.split(',')]\n",
    "    question = [x.split(',') for x in question_encode]\n",
    "    question=[[int(float(item)) for item in x] for x in question]\n",
    "    vgg = self.video_feature.root.vgg[video_id]\n",
    "    c3d = self.video_feature.root.c3d[video_id]\n",
    "\n",
    "    self.test_example_idx += self.train_batch_size\n",
    "    if self.test_example_idx == self.test_example_total:\n",
    "        self.has_test_example = False\n",
    "\n",
    "    return vgg, c3d, question, answer, example_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0265579223632812e-05\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "# np.sum(np.eye(4000)[[1,2]], axis=0)\n",
    "# a = np.zeros([1,4000])\n",
    "# b = [1, 2000,3999]\n",
    "# for line in b:\n",
    "#     for i in range(3999):\n",
    "#         a[0][i] = 1\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc.n_values_ is: [2 3 4]\n",
      "enc.feature_indices_ is: [0 2 5 9]\n",
      "[[1. 0. 0. 1. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]]) \n",
    "print (\"enc.n_values_ is:\",enc.n_values_)\n",
    "print (\"enc.feature_indices_ is:\",enc.feature_indices_)\n",
    "print (enc.transform([[0, 1, 1]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc.n_values_ is: [1 3 4]\n",
      "enc.feature_indices_ is: [0 1 4 8]\n",
      "[[1. 0. 1. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit([[0, 0, 3], [0, 1, 0], [0, 2, 1], [0, 0, 2]]) \n",
    "print (\"enc.n_values_ is:\",enc.n_values_)\n",
    "print (\"enc.feature_indices_ is:\",enc.feature_indices_)\n",
    "print (enc.transform([[0, 1, 1]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc.n_values_ is: [3 1 5]\n",
      "enc.feature_indices_ is: [0 3 4 9]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unknown categorical feature present [1] during transform.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6b3d57c4acd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"enc.n_values_ is:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_values_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"enc.feature_indices_ is:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_indices_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   2073\u001b[0m         \"\"\"\n\u001b[1;32m   2074\u001b[0m         return _transform_selected(X, self._transform,\n\u001b[0;32m-> 2075\u001b[0;31m                                    self.categorical_features, copy=True)\n\u001b[0m\u001b[1;32m   2076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36m_transform_selected\u001b[0;34m(X, transform, selected, copy)\u001b[0m\n\u001b[1;32m   1810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mselected\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1812\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   2044\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'error'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m                 raise ValueError(\"unknown categorical feature present %s \"\n\u001b[0;32m-> 2046\u001b[0;31m                                  \"during transform.\" % X.ravel()[~mask])\n\u001b[0m\u001b[1;32m   2047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2048\u001b[0m         \u001b[0mcolumn_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unknown categorical feature present [1] during transform."
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit([[0, 0, 3], [1, 0, 3], [0, 0, 4], [2, 0, 3]]) \n",
    "print (\"enc.n_values_ is:\",enc.n_values_)\n",
    "print (\"enc.feature_indices_ is:\",enc.feature_indices_)\n",
    "print (enc.transform([[0, 1, 1]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
